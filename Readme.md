

<h1>Python_Labs</h1>

# –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ 1



## –ó–∞–¥–∞–Ω–∏—è

### –ó–∞–¥–∞–Ω–∏–µ 1:

–ü—Ä–æ–≥—Ä–∞–º–º–∞ –≤—ã–≤–æ–¥–∏—Ç –ø—Ä–æ—Å—Ç–æ–µ –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏–µ –≤ –∫–æ–Ω—Å–æ–ª—å.

**–ö–æ–¥:**
```python
name = input("–ò–º—è: ")
age = int(input("–í–æ–∑—Ä–∞—Å—Ç: "))
print(f"–ü—Ä–∏–≤–µ—Ç, {name}! –ß–µ—Ä–µ–∑ –≥–æ–¥ —Ç–µ–±–µ –±—É–¥–µ—Ç {age}.")
```
–†–µ–∑—É–ª—å—Ç–∞—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è:

![–†–µ–∑—É–ª—å—Ç–∞—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–¥–∞–Ω–∏—è 1](images/lab01/01_greeting.png)

### –ó–∞–¥–∞–Ω–∏–µ 2: 

–ö–æ–¥:

```python
a = (input("a: ")).replace(",",".")
b = (input("b: ")).replace(",",".")
print(f"sum={round(float(a)+float(b), 2)}; avg={round((float(a)+float(b))/2, 2)}")
```
–†–µ–∑—É–ª—å—Ç–∞—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è:

![–†–µ–∑—É–ª—å—Ç–∞—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–¥–∞–Ω–∏—è 2](images/lab01/02_sum_avg.png)


### –ó–∞–¥–∞–Ω–∏–µ 3: 

```python
price = int(input())
discount = int(input())
vat = int(input())
base = price * (1 - discount/100)
vat_amount = base * (vat/100)
total = base + vat_amount
print(f"–ë–∞–∑–∞ –ø–æ—Å–ª–µ —Å–∫–∏–¥–∫–∏: {base:.2f} ‚ÇΩ")
print(f"–ù–î–°:               {vat_amount:.2f} ‚ÇΩ")
print(f"–ò—Ç–æ–≥–æ –∫ –æ–ø–ª–∞—Ç–µ:    {total:.2f} ‚ÇΩ")
```
–†–µ–∑—É–ª—å—Ç–∞—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è:

![–†–µ–∑—É–ª—å—Ç–∞—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–¥–∞–Ω–∏—è 3](images/lab01/03_discount_vat.png)

### –ó–∞–¥–∞–Ω–∏–µ 4: 

```python
mm = int(input("–ú–∏–Ω—É—Ç—ã: "))
hh = mm//60
print(f"{hh}:{(mm-60*hh):02d}")
```
–†–µ–∑—É–ª—å—Ç–∞—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è:

![–†–µ–∑—É–ª—å—Ç–∞—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–¥–∞–Ω–∏—è 4](images/lab01/04_minutes_to_hhmm.png)

### –ó–∞–¥–∞–Ω–∏–µ 5:

```python
fio = input("–§–ò–û: ").split()
I = ''
for i in range(3):
    I += fio[i][0]
print(f"–ò–Ω–∏—Ü–∏–∞–ª—ã: {I}.")
print(sum(len(i) for i in fio)+2)
```

–†–µ–∑—É–ª—å—Ç–∞—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è:

![–†–µ–∑—É–ª—å—Ç–∞—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–¥–∞–Ω–∏—è 5](images/lab01/05_initials_and_len.png)


### –ó–∞–¥–∞–Ω–∏–µ 6:
```python
n = int(input())
ochno = 0
for i in range(n):
    surname, name, age, form = map(str, input().split(' '))
    if form == 'True':
        ochno+=1
print(ochno, n-ochno)
```

–†–µ–∑—É–ª—å—Ç–∞—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è:

![–†–µ–∑—É–ª—å—Ç–∞—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–¥–∞–Ω–∏—è 6](images/lab01/ex_06.png)

### –ó–∞–¥–∞–Ω–∏–µ 7:
```python
cipher = input()
ans = ''
n = 0
for i in range(len(cipher)):
    if cipher[i].isupper():
        ans+=cipher[i]
        n = i+1
        break

for i in range(len(cipher)):
    for j in range(2,1000,3):
        if i == n+j:
            ans+=cipher[i]
print(ans)
```

–†–µ–∑—É–ª—å—Ç–∞—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è:

![–†–µ–∑—É–ª—å—Ç–∞—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–¥–∞–Ω–∏—è 1](images/lab01/ex_07.png)


# –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ 2
### –ó–∞–¥–∞–Ω–∏–µ 1:

```python
def min_max(nums):
    if nums==[]:
        return 'ValueError'
    else:
        return (min(nums),max(nums))

def unique_sorted(nums):
    return sorted(set(nums), reverse=False)
def flatten(mat):
    new_mat = []
    for i in mat:
        for j in i:
            if type(j) == str:
                return 'TypeError'
            new_mat.append(j)
    return (new_mat)
```

–†–µ–∑—É–ª—å—Ç–∞—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è:

![–†–µ–∑—É–ª—å—Ç–∞—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–¥–∞–Ω–∏—è 6](images/lab02/arrays.png)

### –ó–∞–¥–∞–Ω–∏–µ 2:

```python

def transpose(mat):
    if len(mat) == 0:
        return []
    elif len(mat) == 1:
        b = [[] for _ in range(len(mat[0]))]
        for i in range(len(mat[0])):
            b[i] += [(mat[0][i])]
        return b
    elif all(len(mat[i]) == 1 for i in range(len(mat))):
        c = [[]]
        for k in mat:
            c[0] += k
        return c
    elif all(len(mat[i]) == len(mat[i + 1]) for i in range(len(mat[0]) - 1)):
        a = [[] for _ in range(len(mat))]
        for k in range(len(mat)):
            for i in range(len(mat[0])):
                a[k] += [mat[i][k]]
        return a
    else:
        return 'ValueError'

def row_sums(mat):
    k = len(mat[0])
    ans = []
    for i in mat:
        if k == len(i):
            ans.append(sum(i))
        else:
            return 'ValueError'
    return ans

def col_sums(mat):
    ans = [0]*len(mat[0])
    k = len(mat[0])
    for i in range(len(mat)):
        if k==len(mat[i]):
            for j in range(len(mat[i])):
                ans[j]+=mat[i][j]
        else:
            return 'ValueError'
    return ans
```

–†–µ–∑—É–ª—å—Ç–∞—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è:

![–†–µ–∑—É–ª—å—Ç–∞—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–¥–∞–Ω–∏—è 6](images/lab02/matrix.png)

### –ó–∞–¥–∞–Ω–∏–µ 3:

```python
fio_new = ''
flag1 = False
len_fio = 0
gpa = float
s = input().replace('(','').replace(')','').split(', ')
for i in s:
    if i == '':
        s.append('musor')
if len(s) == 3:
    fio_old = s[0].replace('''"''','').split(' ')
    for i in fio_old:
        if i != '' and flag1 == False:
            fio_new += str(i.capitalize())+' '
            len_fio+=1
            flag1 = True
        elif flag1 == True and i!='':
            fio_new += str(i.capitalize()[0]) + '.'
            len_fio+=1
    group = s[1].replace('''"''','')
    gpa = float(s[2])
    if 3>=len_fio>=2:
        print(f'''"{fio_new}, –≥—Ä. {group}, GPA {gpa:.2f}"''')
    else:
        print('ValueError')
else: print('ValueError')
```

–†–µ–∑—É–ª—å—Ç–∞—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è:

![–†–µ–∑—É–ª—å—Ç–∞—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–¥–∞–Ω–∏—è 6](images/lab02/tuples.png)


# –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ 3
### –ó–∞–¥–∞–Ω–∏–µ 1:

```python
import re
def normalize(text: str, casefold: bool, yo2e: bool):
    text = ' '.join(text.split())
    if casefold:
        text = text.casefold()
    if yo2e:
        text = text.replace("—ë","–µ").replace('–Å', '–ï')
    return text

print(normalize("–ü—Ä–ò–≤–ï—Ç\n–ú–ò—Ä\t", True,False))
print(normalize("—ë–∂–∏–∫, –Å–ª–∫–∞", False,True))
print(normalize("Hello\r\nWorld", False,False))
print(normalize("  –¥–≤–æ–π–Ω—ã–µ   –ø—Ä–æ–±–µ–ª—ã  ", False,False))
def tokenize(text: str):
    text=text.replace(',', ' ').replace('.',' ')
    return re.sub(r'[^a-zA-Z–∞-—è–ê-–Ø0-9-\s]', '', text).split()
print(tokenize("–ø—Ä–∏–≤–µ—Ç –º–∏—Ä"))
print(tokenize("hello,world!!!"))
print(tokenize("–ø–æ-–Ω–∞—Å—Ç–æ—è—â–µ–º—É –∫—Ä—É—Ç–æ"))
print(tokenize("2025 –≥–æ–¥"))
print(tokenize("emoji üòÄ –Ω–µ —Å–ª–æ–≤–æ"))

def count_freq(tokens: list[str]):
    freq = {}
    for i in tokens:
        if i in freq:
            freq[i] += 1
        else:
            freq[i] = 1
    return freq
def top_n(freq: dict[str, int], n: int):
    s = sorted(freq.items(), key=lambda x: (-x[1], x[0]))
    return s[:n]
print(count_freq(["a","b","a","c","b","a"]))
print(top_n(count_freq(["a","b","a","c","b","a"]),2))
print((count_freq(["bb","aa","bb","aa","cc"])))
print(top_n(count_freq(["bb","aa","bb","aa","cc"]),2))
```

–†–µ–∑—É–ª—å—Ç–∞—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è:

![–†–µ–∑—É–ª—å—Ç–∞—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–¥–∞–Ω–∏—è 1](images/lab03/text.png)

### –ó–∞–¥–∞–Ω–∏–µ 2:

```python
import sys
import io

# true - –∫—Ä–∞—Å–∏–≤—ã–π —Ç–∞–±–ª–∏—á–Ω—ã–π –≤—ã–≤–æ–¥; false - —Å—Ç–∞–Ω–¥–∞—Ä—Ç
PRETTY_TABLE_OUTPUT = True

try:
    sys.stdin = io.TextIOWrapper(sys.stdin.buffer, encoding='utf-8')
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')
except TypeError:
    pass

from text import normalize, tokenize, count_freq, top_n



def print_simple_output(total, unique, top_words):
    print(f"–í—Å–µ–≥–æ —Å–ª–æ–≤: {total}")
    print(f"–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–ª–æ–≤: {unique}")
    print("–¢–æ–ø-5:")
    for word, count in top_words:
        print(f"{word}:{count}")


def print_pretty_table(total, unique, top_words):
    print(f"–í—Å–µ–≥–æ —Å–ª–æ–≤: {total}")
    print(f"–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–ª–æ–≤: {unique}")

    if not top_words:
        print("–¢–æ–ø-5:")
        return

    header_word = "—Å–ª–æ–≤–æ"
    max_len = max([len(word) for word, count in top_words] + [len(header_word)])

    header_freq = "—á–∞—Å—Ç–æ—Ç–∞"

    print(f"{header_word:<{max_len}} | {header_freq}")
    print(f"{'-' * max_len}-+-{'-' * len(header_freq)}")

    for word, count in top_words:
        print(f"{word:<{max_len}} | {count}")


input_text = sys.stdin.read()

normalized_text = normalize(input_text, casefold=True, yo2e=True)
tokens = tokenize(normalized_text)
total_words = len(tokens)

if total_words == 0:
    print("–í—Å–µ–≥–æ —Å–ª–æ–≤: 0")
    print("–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–ª–æ–≤: 0")
    print("–¢–æ–ø-5:")
else:
    freq_dict = count_freq(tokens)
    unique_words = len(freq_dict)
    top_5_words = top_n(freq_dict, 5)

    if PRETTY_TABLE_OUTPUT:
        print_pretty_table(total_words, unique_words, top_5_words)
    else:
        print_simple_output(total_words, unique_words, top_5_words)
```
### –ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ –∫ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—é:

```
–ß—Ç–æ–±—ã –≤—ã–ø–æ–ª–Ω–∏—Ç—å –∫–æ–¥ –¥–ª—è –≤–∏–Ω–¥–æ—É—Å –Ω—É–∂–Ω–æ –∑–∞–ø—É—Å—Ç–∏—Ç—å 
–∫–æ–º–∞–Ω–¥–Ω—É—é —Å—Ç—Ä–æ–∫—É, –ø–µ—Ä–µ–º–µ—Å—Ç–∏—Ç—å—Å—è –≤ —Ñ–∞–π–ª(cd ./–ø—É—Ç—å):
 chcp 65001 && echo –∑–¥–µ—Å—å —Ç–µ–∫—Å—Ç | py text_stats.py
( chcp 65001 - –ø–µ—Ä–µ–≤–æ–¥–∏–º –≤ –∫–æ–¥–∏—Ä–æ–≤–∫—É UTF-8)
PRETTY_TABLE_OUTPUT - —Ä–µ–≥—É–ª–∏—Ä–æ–≤–∫–∞ –≤—ã–≤–æ–¥–∞, –ø–∞—Ä–∞–º–µ—Ç—Ä True - –∫—Ä–∞—Å–∏–≤—ã–π —Ç–∞–±–ª–∏—á–Ω—ã–π –≤—ã–≤–æ–¥
–ø–∞—Ä–∞–º–µ—Ç—Ä False - —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –≤—ã–≤–æ–¥
```

–†–µ–∑—É–ª—å—Ç–∞—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è:

![–†–µ–∑—É–ª—å—Ç–∞—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–¥–∞–Ω–∏—è 2](images/lab03/text_stats.png)



# –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ 4
### –ó–∞–¥–∞–Ω–∏–µ 1:

```python
import csv
from pathlib import Path
from typing import Iterable, Sequence

def ensure_parent_dir(path: str | Path) -> None:
    p = Path(path)
    if p.parent != Path('.'):
        p.parent.mkdir(parents=True, exist_ok=True)

def read_text(path: str | Path, encoding: str = "utf-8") -> str:
    p = Path(path)
    return p.read_text(encoding=encoding)

def write_csv(rows: Iterable[Sequence], path: str | Path, header: tuple[str, ...] | None = None) -> None:
    ensure_parent_dir(path)
    rows = list(rows)
    if rows:
        first_row_len = len(rows[0])
        if not all(len(r) == first_row_len for r in rows):
            raise ValueError("–í—Å–µ —Å—Ç—Ä–æ–∫–∏ –¥–æ–ª–∂–Ω—ã –∏–º–µ—Ç—å –æ–¥–∏–Ω–∞–∫–æ–≤—É—é –¥–ª–∏–Ω—É")
    p = Path(path)
    with p.open("w", newline="", encoding="utf-8") as f:
        writer = csv.writer(f)
        if header is not None:
            writer.writerow(header)
        writer.writerows(rows)
```

![–†–µ–∑—É–ª—å—Ç–∞—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–¥–∞–Ω–∏—è 1](images/lab04/io_txt_csv.png)
![–†–µ–∑—É–ª—å—Ç–∞—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–¥–∞–Ω–∏—è 1](images/lab04/out_io_txt_csv.png)


### –ó–∞–¥–∞–Ω–∏–µ 2:

```python
import argparse
import sys
from collections import Counter
from pathlib import Path
from src.lab03.text import normalize, tokenize, count_freq, top_n
from src.lab04.io_txt_csv import read_text, write_csv


def frequencies_from_text(text: str) -> dict[str, int]:
    norm_text = normalize(text, True, True)
    tokens = tokenize(norm_text)
    return count_freq(tokens)


def main():
    parser = argparse.ArgumentParser(description="–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —á–∞—Å—Ç–æ—Ç–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞.")
    parser.add_argument('--in', dest='in_files', nargs='+', required=True, help="–í—Ö–æ–¥–Ω—ã–µ —Ñ–∞–π–ª—ã")
    parser.add_argument('--out', dest='out_file', default='data/lab04/report.csv', help="–í—ã—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª")
    parser.add_argument('--encoding', default='utf-8', help="–ö–æ–¥–∏—Ä–æ–≤–∫–∞")
    parser.add_argument('--per-file', dest='per_file_report', help="–û—Ç—á–µ—Ç –ø–æ –∫–∞–∂–¥–æ–º—É —Ñ–∞–π–ª—É")
    parser.add_argument('--total', dest='total_report', help="–°–≤–æ–¥–Ω—ã–π –æ—Ç—á–µ—Ç")
    args = parser.parse_args()

    if len(args.in_files) == 1:
        process_single_file(args.in_files[0], args.out_file, args.encoding)
    else:
        if not args.per_file_report or not args.total_report:
            print("–û—à–∏–±–∫–∞: —É–∫–∞–∂–∏—Ç–µ --per-file –∏ --total", file=sys.stderr)
            sys.exit(1)
        process_multiple_files(args.in_files, args.per_file_report, args.total_report, args.encoding)


def process_single_file(in_path: str, out_path: str, encoding: str):
    try:
        text = read_text(in_path, encoding=encoding)
    except (FileNotFoundError, UnicodeDecodeError) as e:
        print(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è '{in_path}': {e}", file=sys.stderr)
        sys.exit(1)
    freq = frequencies_from_text(text)
    sorted_rows = top_n(freq, len(freq))
    write_csv(sorted_rows, out_path, header=("word", "count"))
    print(f"–û—Ç—á–µ—Ç –ø–æ —Ñ–∞–π–ª—É: {in_path}")
    print(f"–°–æ—Ö—Ä–∞–Ω–µ–Ω –≤: {out_path}")
    print("-" * 20)
    print(f"–í—Å–µ–≥–æ —Å–ª–æ–≤: {sum(freq.values())}")
    print(f"–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–ª–æ–≤: {len(freq)}")
    print("–¢–æ–ø-5 —Å–ª–æ–≤:")
    top5 = top_n(freq, 5)
    if not top5:
        print("(–ø—É—Å—Ç–æ)")
    else:
        for word, count in top5:
            print(f"{word}: {count}")


def process_multiple_files(in_paths: list[str], per_file_path: str, total_path: str, encoding: str):
    total_freq = Counter()
    per_file_rows = []

    for path_str in in_paths:
        try:
            text = read_text(path_str, encoding=encoding)
            file_name = Path(path_str).name
            freq = frequencies_from_text(text)
            total_freq.update(freq)
            sorted_file_freq = top_n(freq, len(freq))
            for word, count in sorted_file_freq:
                per_file_rows.append((file_name, word, count))

        except Exception as e:
            print(f"–ü—Ä–æ–ø—É—Å–∫ —Ñ–∞–π–ª–∞ {path_str}: {e}", file=sys.stderr)
            continue

    per_file_rows.sort(key=lambda x: (x[0], -x[2], x[1]))
    write_csv(per_file_rows, per_file_path, header=("file", "word", "count"))
    print(f"–î–µ—Ç–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç: {per_file_path}")
    sorted_total = top_n(dict(total_freq), len(total_freq))
    write_csv(sorted_total, total_path, header=("word", "count"))
    print(f"–°–≤–æ–¥–Ω—ã–π –æ—Ç—á–µ—Ç: {total_path}")


if __name__ == '__main__':
    main()
```

![–†–µ–∑—É–ª—å—Ç–∞—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–¥–∞–Ω–∏—è 2](images/lab04/text_report.png)
![–†–µ–∑—É–ª—å—Ç–∞—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–¥–∞–Ω–∏—è 2](images/lab04/in_text_report.png)
![–†–µ–∑—É–ª—å—Ç–∞—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–¥–∞–Ω–∏—è 2](images/lab04/out_text_report.png)


# –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ 5
### –ó–∞–¥–∞–Ω–∏–µ 1:

```python
from pathlib import Path
import json
import csv
from typing import List,Dict,Any

def check_file_found(path: str) -> Path:
    p = Path(path)
    if not p.exists():
        raise FileNotFoundError(f"File not found: {path}")
    return p

def load_json(path: str)-> List[Dict[str, Any]]:
    p = check_file_found(path)
    text = p.read_text(encoding="utf-8")
    if text.strip() == "":
        raise ValueError
    try:
        data = json.loads(text)
    except json.JSONDecodeError:
        raise ValueError
    if not isinstance(data,list) or len(data)==0 or not all(isinstance(item,dict) for item in data):
        raise ValueError
    return data


def json_to_csv(json_path: str, csv_path: str) -> None:
    data = load_json(json_path)
    fieldnames = list(data[0].keys())
    csv_file = Path(csv_path)
    with csv_file.open("w", encoding="utf-8", newline="") as f:
        writer = csv.DictWriter(f, fieldnames, extrasaction="ignore")
        writer.writeheader()
        for row in data:
            writer.writerow({k: row.get(k, "") for k in fieldnames})

def csv_to_json(csv_path:str, json_path: str) -> None:
    p = check_file_found(csv_path)
    with p.open("r", encoding="utf-8", newline="") as f:
        reader = csv.DictReader(f)
        if not reader.fieldnames:
            raise ValueError
        data = [dict(row) for row in reader]
    out = Path(json_path)
    with out.open("w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

if __name__ == "__main__":
    try:
        json_to_csv("data/people.json", "data/people.csv")
        csv_to_json("data/people.csv", "data/people.jso" )
    except Exception as e:
        print("–û—à–∏–±–∫–∞:", e)
```


–†–µ–∑—É–ª—å—Ç–∞—Ç —Ä–∞–±–æ—Ç—ã —Ñ—É–Ω–∫—Ü–∏–∏ json_to_csv

–í—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª [people.json](src/lab05/data/people.json)

–í—ã—Ö–æ–¥–Ω–æ–π [people.csv](src/lab05/data/people.csv)

–†–µ–∑—É–ª—å—Ç–∞—Ç —Ä–∞–±–æ—Ç—ã —Ñ—É–Ω–∫—Ü–∏–∏ csv_to_json

–í—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª [people.csv](src/lab05/data/people.csv)

–í—ã—Ö–æ–¥–Ω–æ–π [people.json](src/lab05/data/people.json)


### –ó–∞–¥–∞–Ω–∏–µ 2:

```python
import csv
from pathlib import Path
import openpyxl.utils
from openpyxl import Workbook

def csv2xlsx(csv_path: str, xlsx_path:str):
    p = Path(csv_path)
    if not p.exists():
        raise FileNotFoundError
    with p.open("r", encoding="utf-8") as f:
        reader = csv.reader(f)
        rows = list(reader)
        if len(rows)==0 or len((rows[0])) == 0:
            raise ValueError


    wb = Workbook()
    ws = wb.active
    ws.title = "Sheet1"
    for row in rows:
        ws.append(row)
    num_cols = len(rows[0])
    cols_w = [0]*num_cols
    for row in rows:
        for i, cell in enumerate(row):
            cols_w[i] = max(cols_w[i], len((str(cell))))
    for i, width in enumerate(cols_w,start=1):
        ws.column_dimensions[openpyxl.utils.get_column_letter(i)].width = max(8,width)
    wb.save(xlsx_path)

if __name__ == "__main__":
    try:
        csv2xlsx('data/people.csv', 'data/people.xlsx')
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞: {e}")
```

–†–µ–∑—É–ª—å—Ç–∞—Ç —Ä–∞–±–æ—Ç—ã —Ñ—É–Ω–∫—Ü–∏–∏ csv2xlsx

–í—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª [people.csv](src/lab05/data/people.csv)
–í—ã—Ö–æ–¥–Ω–æ–π [people.xlsx](src/lab05/data/people.xlsx)


# –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ 6:

# –ó–∞–¥–∞–Ω–∏–µ 1:

```python
import argparse
import sys

from src.lab05.csv_xlsx import csv2xlsx
from src.lab05.json_csv import json_to_csv,csv_to_json

def json2csv_command(args):
    try:
        json_to_csv(args.infile, args.out)
        print(f"–£—Å–ø–µ—à–Ω–æ –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ: {args.infile} -> {args.out}")
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ JSON –≤ CSV: {e}")
        sys.exit(1)


def csv2json_command(args):
    try:
        csv_to_json(args.infile, args.out)
        print(f"–£—Å–ø–µ—à–Ω–æ –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ: {args.infile} -> {args.out}")
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ CSV –≤ JSON: {e}")
        sys.exit(1)


def csv2xlsx_command(args):
    try:
        csv2xlsx(args.infile, args.out)
        print(f"–£—Å–ø–µ—à–Ω–æ –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ: {args.infile} -> {args.out}")
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ CSV –≤ XLSX: {e}")
        sys.exit(1)


def main():
    parser = argparse.ArgumentParser(description="–ö–æ–Ω–≤–µ—Ä—Ç–µ—Ä –º–µ–∂–¥—É —Ñ–æ—Ä–º–∞—Ç–∞–º–∏ –¥–∞–Ω–Ω—ã—Ö")

    subparsers = parser.add_subparsers(dest="command", help="–î–æ—Å—Ç—É–ø–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã")

    json2csv_parser = subparsers.add_parser("json2csv", help="–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è JSON –≤ CSV")
    json2csv_parser.add_argument(
        "--input", dest="infile", required=True, help="–í—Ö–æ–¥–Ω–æ–π JSON —Ñ–∞–π–ª"
    )
    json2csv_parser.add_argument("--out", required=True, help="–í—ã—Ö–æ–¥–Ω–æ–π CSV —Ñ–∞–π–ª")

    csv2json_parser = subparsers.add_parser("csv2json", help="–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è CSV –≤ JSON")
    csv2json_parser.add_argument(
        "--input", dest="infile", required=True, help="–í—Ö–æ–¥–Ω–æ–π CSV —Ñ–∞–π–ª"
    )
    csv2json_parser.add_argument("--out", required=True, help="–í—ã—Ö–æ–¥–Ω–æ–π JSON —Ñ–∞–π–ª")

    csv2xlsx_parser = subparsers.add_parser("csv2xlsx", help="–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è CSV –≤ XLSX")
    csv2xlsx_parser.add_argument(
        "--input", dest="infile", required=True, help="–í—Ö–æ–¥–Ω–æ–π CSV —Ñ–∞–π–ª"
    )
    csv2xlsx_parser.add_argument("--out", required=True, help="–í—ã—Ö–æ–¥–Ω–æ–π XLSX —Ñ–∞–π–ª")

    args = parser.parse_args()

    if args.command == "json2csv":
        json2csv_command(args)
    elif args.command == "csv2json":
        csv2json_command(args)
    elif args.command == "csv2xlsx":
        csv2xlsx_command(args)
    else:
        parser.print_help()


if __name__ == "__main__":
    main()
```

–†–µ–∑—É–ª—å—Ç–∞—Ç —Ä–∞–±–æ—Ç–∞:
    
    –†–µ–∑—É–ª—å—Ç–∞—Ç —Ä–∞–±–æ—Ç—ã –∫–æ–º–∞–Ω–¥—ã json2csv --input INPUT --out OUT
    
        –í—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª people.json
    
        –í—ã—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª people.csv
    
    –†–µ–∑—É–ª—å—Ç–∞—Ç —Ä–∞–±–æ—Ç—ã –∫–æ–º–∞–Ω–¥—ã csv2json --input INPUT --out OUT
    
        –í—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª input.csv
    
        –í—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª people.json
    
    –†–µ–∑—É–ª—å—Ç–∞—Ç —Ä–∞–±–æ—Ç—ã –∫–æ–º–∞–Ω–¥—ã csv2xlsx --input INPUT --out OUT
    
        –í—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª input.csv

        –í—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª people.xlsx

# –ó–∞–¥–∞–Ω–∏–µ 2:

```python
import argparse
import sys

from src.lab03.text import count_freq, normalize, tokenize, top_n
def read_text_file(file_path):
    try:
        with open(file_path, "r", encoding="utf-8") as f:
            return f.read()
    except FileNotFoundError:
        print(f"–û—à–∏–±–∫–∞: –§–∞–π–ª {file_path} –Ω–µ –Ω–∞–π–¥–µ–Ω")
        sys.exit(1)
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞: {e}")
        sys.exit(1)


def stats_command(args):
    text = read_text_file(args.input)
    normalized_text = normalize(text)
    tokens = tokenize(normalized_text)
    frequencies = count_freq(tokens)
    top_5 = top_n(frequencies, args.top)

    print("–¢–æ–ø-5:")

    for item in top_5:
        print(f"{item[0]}: {item[1]}")


def cat_command(args):
    try:
        with open(args.input, "r", encoding="utf-8") as f:
            for line_num, line in enumerate(f, 1):
                if args.n:
                    print(f"{line_num:6}  {line}", end="")
                else:
                    print(line, end="")
    except FileNotFoundError:
        print(f"–û—à–∏–±–∫–∞: –§–∞–π–ª {args.input} –Ω–µ –Ω–∞–π–¥–µ–Ω")
        sys.exit(1)
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞: {e}")
        sys.exit(1)


def main():
    parser = argparse.ArgumentParser(description="–£—Ç–∏–ª–∏—Ç—ã –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å —Ç–µ–∫—Å—Ç–æ–º")
    subparsers = parser.add_subparsers(dest="command", help="–î–æ—Å—Ç—É–ø–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã")

    cat_parser = subparsers.add_parser("cat", help="–í—ã–≤–æ–¥ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ —Ñ–∞–π–ª–∞")
    cat_parser.add_argument("--input", required=True, help="–ü—É—Ç—å –∫ —Ñ–∞–π–ª—É")
    cat_parser.add_argument("-n", action="store_true", help="–ù—É–º–µ—Ä–æ–≤–∞—Ç—å —Å—Ç—Ä–æ–∫–∏")

    stats_parser = subparsers.add_parser("stats", help="–ê–Ω–∞–ª–∏–∑ —á–∞—Å—Ç–æ—Ç —Å–ª–æ–≤ –≤ —Ç–µ–∫—Å—Ç–µ")
    stats_parser.add_argument("--input", required=True, help="–í—Ö–æ–¥–Ω–æ–π —Ç–µ–∫—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª")
    stats_parser.add_argument(
        "--top", type=int, default=5, help="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–ø —Å–ª–æ–≤ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: 5)"
    )

    args = parser.parse_args()

    if args.command == "stats":
        stats_command(args)
    elif args.command == "cat":
        cat_command(args)
    else:
        parser.print_help()


if __name__ == "__main__":
    main()
```

–†–µ–∑—É–ª—å—Ç–∞—Ç —Ä–∞–±–æ—Ç—ã: 


–†–µ–∑—É–ª—å—Ç–∞—Ç —Ä–∞–±–æ—Ç—ã –∫–æ–º–∞–Ω–¥—ã cat --input INPUT -n

–í—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª [input.txt](src/lab06/data/samples/input.txt)

–í—ã–≤–æ–¥ [...](images/lab06/out_cat.png)

–í—ã–≤–æ–¥

–†–µ–∑—É–ª—å—Ç–∞—Ç —Ä–∞–±–æ—Ç—ã –∫–æ–º–∞–Ω–¥—ã stats --input INPUT --top 5

–í—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª input.txt

–í—ã–≤–æ–¥ [...](images/lab06/out_cat.png)


# –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ ‚Ññ6

# –ó–∞–¥–∞–Ω–∏–µ 1:
–ö–û–î:

```python
@pytest.mark.parametrize(
    "text, expected",
    [
        ("–ü—Ä–ò–≤–ï—Ç\n–ú–ò—Ä\t", "–ø—Ä–∏–≤–µ—Ç –º–∏—Ä"),
        ("—ë–∂–∏–∫, –Å–ª–∫–∞", "–µ–∂–∏–∫, –µ–ª–∫–∞"),
        ("Hello\r\nWorld", "hello world"),
        ("  –¥–≤–æ–π–Ω—ã–µ   –ø—Ä–æ–±–µ–ª—ã  ", "–¥–≤–æ–π–Ω—ã–µ –ø—Ä–æ–±–µ–ª—ã"),
        ("", ""),
        ("   ", ""),
        ("Simple Text", "simple text"),
    ],
)
def test_normalize(text, expected):
    assert normalize(text, True, True) == expected


@pytest.mark.parametrize(
    "text, expected",
    [
        ("–ø—Ä–∏–≤–µ—Ç –º–∏—Ä", ["–ø—Ä–∏–≤–µ—Ç", "–º–∏—Ä"]),
        ("hello,world!!!", ["hello", "world"]),
        ("–ø–æ-–Ω–∞—Å—Ç–æ—è—â–µ–º—É –∫—Ä—É—Ç–æ", ["–ø–æ-–Ω–∞—Å—Ç–æ—è—â–µ–º—É", "–∫—Ä—É—Ç–æ"]),
        ("2025 –≥–æ–¥", ["2025", "–≥–æ–¥"]),
        ("emoji üòÄ –Ω–µ —Å–ª–æ–≤–æ", ["emoji", "–Ω–µ", "—Å–ª–æ–≤–æ"]),
        ("", []),
        ("!!! ... ,,,", []),
    ],
)
def test_tokenize(text, expected):
    assert tokenize(text) == expected


@pytest.mark.parametrize(
    "tokens, expected",
    [
        (["a", "b", "a", "c", "b", "a"], {"a": 3, "b": 2, "c": 1}),
        (["bb", "aa", "bb", "aa", "cc"], {"aa": 2, "bb": 2, "cc": 1}),
        ([], {}),
        (["word"], {"word": 1}),
        (["a", "a", "a"], {"a": 3}),
    ],
)
def test_count_freq(tokens, expected):
    assert count_freq(tokens) == expected


@pytest.mark.parametrize(
    "freq, n, expected",
    [
        ({"a": 3, "b": 2, "c": 1}, 2, [("a", 3), ("b", 2)]),
        ({"aa": 2, "bb": 2, "cc": 1}, 2, [("aa", 2), ("bb", 2)]),
        ({"banana": 1, "apple": 1}, 2, [("apple", 1), ("banana", 1)]),
        ({}, 5, []),
        ({"a": 10}, 0, []),
        ({"a": 5}, 10, [("a", 5)]),
    ],
)
def test_top_n(freq, n, expected):
    assert top_n(freq, n) == expected
```

# –ó–∞–¥–∞–Ω–∏–µ 2:

–ö–û–î:
```python
import csv
import json
import pytest
from src.lab05.json_csv import csv_to_json, json_to_csv


@pytest.fixture
def json_file(tmp_path):
    json_file = tmp_path / "people.json"
    data = [
        {"name": "Alice", "age": 25, "city": "Moscow"},
    ]
    with open(json_file, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False)
    return json_file


def test_json_to_csv(json_file, tmp_path):
    csv_output = tmp_path / "output.csv"
    json_to_csv(str(json_file), str(csv_output))
    assert csv_output.exists()
    with open(csv_output, "r", encoding="utf-8") as f:
        reader = csv.DictReader(f)
        rows = list(reader)
        assert reader.fieldnames == ["name", "age", "city"]
        assert rows[0]["name"] == "Alice"
        assert rows[0]["age"] == "25"
        assert rows[0]["city"] == "Moscow"


@pytest.fixture
def csv_file(tmp_path):
    """–§–∏–∫—Å—Ç—É—Ä–∞ —Å–æ–∑–¥–∞–µ—Ç —Ç–µ—Å—Ç–æ–≤—ã–π CSV —Ñ–∞–π–ª"""
    csv_file = tmp_path / "people.csv"
    data = [
        {"name": "Alice", "age": "25", "city": "Moscow"},
    ]
    with open(csv_file, "w", encoding="utf-8", newline="") as f:
        writer = csv.DictWriter(f, fieldnames=["name", "age", "city"])
        writer.writeheader()
        writer.writerows(data)
    return csv_file


def test_csv_to_json(csv_file, tmp_path):
    """–¢–µ—Å—Ç –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ CSV –≤ JSON"""
    json_output = tmp_path / "output.json"
    csv_to_json(str(csv_file), str(json_output))
    assert json_output.exists()
    with open(json_output, "r", encoding="utf-8") as f:
        data = json.load(f)
        assert data[0]["name"] == "Alice"
        assert data[0]["age"] == "25"
        assert data[0]["city"] == "Moscow"

```


# –†–µ–∑—É–ª—å—Ç–∞—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è:
[tests](images/lab07/tests.png)